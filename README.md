# LSC eye-tracker (Learning Single Camera Eye-Tracker)
This repo is for eye track research

We are in the process of preparing dataset for free public release now.
## Data generation
* `generate-dataset.py` generate `.npz` data package for training from the MPIIFaceGaze dataset.
  * MPIIFaceGaze dataset assigned folder with different subjects and then different days' images data
  * We can read the directory from the `p%d%d.txt` file to obtain the complete path for each images file and the corresponding gaze point on the screen
  * The screen size parameters inside the codes should be modified according to the values inside the `screenSize.mat` file in the `Calibration` folder
  * The saved `.npz` file contains two fields: faceData(nSample * rows * cols * channels); eyeTrackData(nSamples * v_grids * h_grids * 3(relative x, y, and probability p))
```
python generate-dataset.py <dataset folder (e.g., ./p00)> <saved .npz file name>
```
## Model training
* `i2g_g_v1.0.py` previous code for model training, use matlab data file as input.
  * The `.mat` file should contain two fields, the same as instructed above in the `generate-dataset.py`
```
python i2g_g_v1.0.py <.mat data file (v7.3)> | tee <logfile>.txt
```
* `i2g_train.py` train the model with .npz dataset generated by `generate-dataset.py`, save model file .h5.
```
python i2g_train.py <.npz data file name> <model name for saving> [<for continuously training model file .h5>]
```
## Model prediction and visualing the results
* `predict-gaze.py` predict gaze point and display both the orginal image and gaze point with trained model .h5 and file list .txt. 
```
  * The setting is the same as the MPIIFaceGaze data generation
python predict-gaze.py <trained model file .h5> <file list file .txt (e.g., p00.txt)>
```
## Standard
* Python code should follow Google style
